# Evaluation Script Guide

## Overview

`Evaluate_metrics.py` is an offline evaluation script that computes and visualizes reconstruction metrics (MAE, PSNR, MS-SSIM) for synthetic CT (sCT) volumes generated by the conditional DDPM model.

## Pipeline

The complete evaluation pipeline consists of three steps:

```bash
# Step 1: Train the model (verify MAE convergence)
python Train_condition.py

# Step 2: Generate sCT volumes for test set
python Test_condition.py

# Step 3: Offline evaluation (compute all metrics)
python Evaluate_metrics.py
```

## Requirements

Before running the evaluation script, ensure:

1. **Training completed**: `./Checkpoints_3D/test_split.json` exists
2. **Inference completed**: `./test_results_3d/` contains generated sCT volumes (`{pid}_sct.mha`)
3. **Dataset accessible**: Ground truth CT and masks are available at `dataset_root`

## Output Files

All results are saved to `./test_results_3d/`:

| File | Description |
|------|-------------|
| `per_patient_metrics.csv` | Complete table with per-patient MAE, PSNR, MS-SSIM |
| `evaluation_summary.txt` | Mean ± standard deviation for each metric |
| `representative_cases.txt` | Best, average, and worst cases (selected by MAE) |
| `histogram_mae.png` | MAE distribution histogram |
| `histogram_psnr.png` | PSNR distribution histogram |
| `histogram_ssim.png` | MS-SSIM distribution histogram |

## Metrics Computed

### MAE (Mean Absolute Error)
- **Units**: HU (Hounsfield Units)
- **Interpretation**: Lower is better
- **Description**: Average voxel-wise absolute difference within body mask

### PSNR (Peak Signal-to-Noise Ratio)
- **Units**: dB (decibels)
- **Interpretation**: Higher is better
- **Description**: Computed using population-wide dynamic range [-1024, 3000] HU

### MS-SSIM (Multi-Scale Structural Similarity)
- **Units**: Dimensionless [0, 1]
- **Interpretation**: Higher is better (1 = perfect match)
- **Description**: Masked version computed within body region across 5 scales

## Representative Case Selection

Representative cases are automatically selected based on **MAE only**:

- **Best case**: Patient with lowest MAE (best reconstruction)
- **Average case**: Patient with MAE closest to dataset mean
- **Worst case**: Patient with highest MAE (worst reconstruction)

For each selected patient, all three metrics (MAE, PSNR, MS-SSIM) are reported.

## Visualization

Histograms include:
- Distribution of metric values across test set
- Red dashed line at mean value
- Gray shaded region for mean ± std
- Text box with summary statistics (mean, std, N)

## Configuration

Edit these variables in `Evaluate_metrics.py` if needed:

```python
dataset_root = "/mnt/asgard0/users/p25_2025/synthRAD2025_Task2_Train/synthRAD2025_Task2_Train/Task2"
save_dir = "./Checkpoints_3D"
output_dir = "./test_results_3d"
```

## Error Handling

The script includes robust error handling:

- **Missing files**: Patients with missing CT, sCT, or mask are skipped with warnings
- **No mask**: If mask is missing, full volume is used
- **Computation errors**: Individual patient failures don't stop evaluation

## Example Output

```
============================================================
Offline Evaluation of sCT Reconstruction Metrics
============================================================

[1/5] Loading test patient information...

Loaded 15 test patients from ./Checkpoints_3D/test_split.json
Found 15 patients with complete data

[2/5] Computing metrics for all patients...
Processing patients: 100%|████████████| 15/15 [05:23<00:00, 21.6s/it]

[3/5] Computing statistics and saving results...
  Saved per-patient metrics: ./test_results_3d/per_patient_metrics.csv
  Saved summary statistics: ./test_results_3d/evaluation_summary.txt

============================================================
SUMMARY STATISTICS
============================================================
Number of patients: 15

Mean ± Standard Deviation:
------------------------------------------------------------
MAE:     45.32 ± 8.15 HU
PSNR:    28.45 ± 2.31 dB
MS-SSIM: 0.8234 ± 0.0456
============================================================

[4/5] Selecting representative cases (based on MAE)...
  Saved representative cases: ./test_results_3d/representative_cases.txt

============================================================
REPRESENTATIVE CASES (selected by MAE)
============================================================

BEST CASE:
  Patient ID: P_001
  MAE:        32.15 HU
  PSNR:       31.24 dB
  MS-SSIM:    0.8756

AVERAGE CASE:
  Patient ID: P_007
  MAE:        44.89 HU
  PSNR:       28.67 dB
  MS-SSIM:    0.8201

WORST CASE:
  Patient ID: P_013
  MAE:        61.23 HU
  PSNR:       25.12 dB
  MS-SSIM:    0.7543
============================================================

[5/5] Generating histograms...
  Saved histogram: ./test_results_3d/histogram_mae.png
  Saved histogram: ./test_results_3d/histogram_psnr.png
  Saved histogram: ./test_results_3d/histogram_ssim.png

============================================================
EVALUATION COMPLETE!
============================================================

All results saved to: ./test_results_3d

Generated files:
  - per_patient_metrics.csv
  - evaluation_summary.txt
  - representative_cases.txt
  - histogram_mae.png
  - histogram_psnr.png
  - histogram_ssim.png
============================================================
```

## Notes

- **Computational efficiency**: PSNR and MS-SSIM are expensive, which is why evaluation is decoupled from training and inference
- **Reproducibility**: The script is fully deterministic (no randomness)
- **Memory efficiency**: Processes one patient at a time
- **Progress tracking**: Uses tqdm for visual feedback during metric computation
